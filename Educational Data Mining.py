# -*- coding: utf-8 -*-
"""Katta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OK7azl-GJY5rgJC8qxMW1icSGWZQ_c-U
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing the basic librarires fot analysis

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("ggplot")  #using style ggplot

# %matplotlib inline
import plotly.graph_objects as go
import plotly.express as px
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# importing Dataset
students_data=pd.read_csv("students_adaptability_level_online_education.csv")
students_data

# looking the shape DataSet
students_data.shape

#Checking the dtypes of all the columns
students_data.info()

# missing value

students_data.isnull().sum()

# look  describe data set

students_data.describe().T

# Show the percentage Adaptivity Level in Dataset

plt.figure(figsize=(12,8))
students_data['Adaptivity Level'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True)

# Show the percentage Gender in Dataset

plt.figure(figsize=(12,8))

students_data['Gender'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True)

# Show the Device using in Dataset

plt.figure(figsize=(12,8))


students_data['Device'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True)

i = 1
plt.figure(figsize = (15,25))
for feature in students_data:
    plt.subplot(6,3,i)
    sns.countplot(x = feature ,  data = students_data)
    i +=1

i = 1
plt.figure(figsize = (15,25))
for feature in students_data:
    plt.subplot(6,3,i)
    sns.countplot(x = feature , hue='Adaptivity Level', data = students_data)
    i +=1

from sklearn.preprocessing import LabelEncoder,StandardScaler
# change all data type using LabelEncode

data=students_data

label_encoders = {}
categorical_columns = data.columns 

for column in categorical_columns:
    label_encoders[column] = LabelEncoder()
    data[column] = label_encoders[column].fit_transform(data[column])

#Independent variables (x)
X_variables = data.drop(["Adaptivity Level"], axis=1)

#Dependent variable (y)
y_variable = data["Adaptivity Level"]

# Scale the X_variable using MinMaxScaler
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_variables_scaled = scaler.fit_transform(X_variables)

# Split the data into training (75%) and testing sets (25%)
X_train, X_test, y_train, y_test = train_test_split(X_variables_scaled, y_variable, test_size=0.25, random_state=42)

# Create a DecisionTreeClassifier object
RF_model = RandomForestClassifier(n_estimators=100, random_state=123)

# Train the classifier on the training data
RF_model.fit(X_train, y_train)

# Predict the class labels of the test data
y_pred = RF_model.predict(X_test)

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix


print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier

# Create a DecisionTreeClassifier object
DT_model = DecisionTreeClassifier(random_state=42)

# Train the classifier on the training data
DT_model.fit(X_train, y_train)

# Predict the class labels of the test data
y_pred = DT_model.predict(X_test)

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

# Calculate recall
recall = recall_score(y_test, y_pred, average='macro')

# Calculate precision
precision = precision_score(y_test, y_pred, average='macro')

# Calculate F1-Score
f1_score = f1_score(y_test, y_pred, average='macro')


# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Print the results
print("Accuracy:", accuracy)
print("Recall:", recall)
print("Precision:", precision)
print("F1-Score:", f1_score)
print("Confusion matrix:\n", cm)

from sklearn.svm import SVC
# Create a svc object
SVC_model = SVC(kernel='linear', C=2, gamma='auto', probability=True, random_state=42)

# Train the classifier on the training data
SVC_model.fit(X_train, y_train)

# Predict the class labels of the test data
y_pred = SVC_model.predict(X_test)

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='macro'))
print("Recall:", recall_score(y_test, y_pred, average='macro'))
print("F1 Score:", f1_score(y_test, y_pred, average='macro'))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))